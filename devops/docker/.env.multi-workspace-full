# ============================================================================
# Sibyl Multi-Workspace Full Setup Configuration
# ============================================================================
# Use this configuration to run multiple workspaces in parallel with both
# MCP and HTTP servers for each workspace.
#
# This setup provides:
# - 2 MCP servers (local + production)
# - 2 HTTP servers (local + production)
# - Full observability stack
# - Shared resources and networking
#
# Usage:
#   docker-compose --env-file .env.multi-workspace-full --profile multi-workspace up -d
#
# Or with observability:
#   docker-compose --env-file .env.multi-workspace-full \
#     --profile multi-workspace \
#     --profile observability up -d
#
# ============================================================================

# ============================================================================
# Workspace Configuration
# ============================================================================

# Local development workspace
SIBYL_WORKSPACE_LOCAL=config/workspaces/example_local.yaml

# Production workspace
SIBYL_WORKSPACE_PROD=config/workspaces/prod_web_research.yaml

# Optional: RAG workspace
# SIBYL_WORKSPACE_RAG=config/workspaces/cloud_rag.yaml

# Optional: Agentic research workspace
# SIBYL_WORKSPACE_RESEARCH=config/workspaces/agentic_research.yaml

# ============================================================================
# MCP Server Port Mapping
# ============================================================================

# Main MCP server (original)
MCP_HTTP_HOST=0.0.0.0
MCP_HTTP_PORT=8770

# Multi-workspace MCP servers
MCP_LOCAL_WORKSPACE_PORT=8771
MCP_PROD_WORKSPACE_PORT=8772

# Optional: Additional workspace ports
# MCP_RAG_WORKSPACE_PORT=8773
# MCP_RESEARCH_WORKSPACE_PORT=8774

# ============================================================================
# HTTP Server Port Mapping
# ============================================================================

# Multi-workspace HTTP servers
HTTP_LOCAL_WORKSPACE_PORT=8000
HTTP_PROD_WORKSPACE_PORT=8001

# Optional: Additional HTTP servers
# HTTP_RAG_WORKSPACE_PORT=8002
# HTTP_RESEARCH_WORKSPACE_PORT=8003

# ============================================================================
# Logging Configuration
# ============================================================================

MCP_LOG_LEVEL=INFO
MCP_JSON_LOGS=true

# ============================================================================
# Resource Allocation
# ============================================================================

# Memory limits per workspace
DUCKDB_MEMORY_LIMIT=2GB

# ============================================================================
# Build Configuration
# ============================================================================

BUILD_TARGET=runtime
VERSION=latest
BUILD_DATE=2025-01-15
VCS_REF=main

# ============================================================================
# Observability Configuration (Optional)
# ============================================================================

# Prometheus
PROMETHEUS_PORT=9090

# Grafana
GRAFANA_PORT=3000
GRAFANA_USER=admin
GRAFANA_PASSWORD=sibyl-admin-pwd

# Loki (log aggregation)
LOKI_PORT=3100

# Jaeger (distributed tracing)
JAEGER_UI_PORT=16686
JAEGER_COLLECTOR_PORT=14268

# ============================================================================
# Quality Control & Metrics
# ============================================================================

MCP_QC_ENABLED=true
MCP_METRICS_ENABLED=true
USE_QUORUM_FOR_SQL_FIXES=false
QUORUM_BUDGET_USD=10.0

# ============================================================================
# Container Orchestration Notes
# ============================================================================
#
# With this configuration, the following services will run:
#
# 1. MCP Local (Port 8771)
#    - Workspace: example_local.yaml
#    - Usage: Local LLM (Ollama) + Sentence Transformers
#    - Best for: Development and testing
#
# 2. MCP Production (Port 8772)
#    - Workspace: prod_web_research.yaml
#    - Usage: Cloud LLM (OpenAI) + Cloud embeddings
#    - Best for: Production workloads
#
# 3. HTTP Local (Port 8000)
#    - Workspace: example_local.yaml
#    - Usage: REST API for local workspace
#
# 4. HTTP Production (Port 8001)
#    - Workspace: prod_web_research.yaml
#    - Usage: REST API for production workspace
#
# 5. Observability Stack (if enabled):
#    - Prometheus: Port 9090 (metrics collection)
#    - Grafana: Port 3000 (visualization)
#    - Loki: Port 3100 (log aggregation)
#    - Jaeger: Port 16686 (distributed tracing)
#
# ============================================================================

# ============================================================================
# Quick Start Commands
# ============================================================================
#
# 1. Start multi-workspace setup:
#    docker-compose --env-file .env.multi-workspace-full \
#      --profile multi-workspace up -d
#
# 2. View logs for local MCP:
#    docker-compose logs -f mcp-local-workspace
#
# 3. Health check all services:
#    curl http://localhost:8771/api/health  # MCP Local
#    curl http://localhost:8772/api/health  # MCP Prod
#    curl http://localhost:8000/api/health  # HTTP Local
#    curl http://localhost:8001/api/health  # HTTP Prod
#
# 4. Stop all services:
#    docker-compose down
#
# 5. View running containers:
#    docker-compose ps
#
# ============================================================================
